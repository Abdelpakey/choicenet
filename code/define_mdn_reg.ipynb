{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture Density Network for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbloader,os,warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from sklearn.utils import shuffle\n",
    "from util import gpusession,create_gradient_clipping,data4reg,plot_1dRegData,print_n_txt\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "if __name__ == \"__main__\":\n",
    "    print (\"TensorFlow version is [%s].\"%(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MDN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mdn_reg_class(object):\n",
    "    def __init__(self,_name='MDN',_xdim=1,_ydim=1,_hdims=[64,64],_sigmax=0\n",
    "                 ,_kmix=5,_actv=tf.nn.relu,_bn=slim.batch_norm\n",
    "                 ,_l2_reg_coef=1e-5,_GPU_ID=0,_VERBOSE=True):\n",
    "        self.name = _name\n",
    "        self.xdim = _xdim\n",
    "        self.ydim = _ydim\n",
    "        self.hdims = _hdims\n",
    "        self.sigmax = _sigmax\n",
    "        self.kmix = _kmix\n",
    "        self.actv = _actv \n",
    "        self.bn   = _bn # slim.batch_norm / None\n",
    "        self.l2_reg_coef = _l2_reg_coef # L2 regularizer \n",
    "        self.GPU_ID = _GPU_ID\n",
    "        self.VERBOSE = _VERBOSE\n",
    "        with tf.device('/device:GPU:%d'%(self.GPU_ID)):\n",
    "            # Build model\n",
    "            self.build_model()\n",
    "            # Build graph\n",
    "            self.build_graph()\n",
    "            # Check parameters\n",
    "            self.check_params()\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.x = tf.placeholder(dtype=tf.float32,shape=[None,self.xdim]) # Input [N x xdim]\n",
    "        self.t = tf.placeholder(dtype=tf.float32,shape=[None,self.ydim]) # Output [N x ydim]\n",
    "        self.kp = tf.placeholder(dtype=tf.float32,shape=[]) # Keep probability \n",
    "        self.lr = tf.placeholder(dtype=tf.float32,shape=[]) # Learning rate\n",
    "        self.is_training = tf.placeholder(dtype=tf.bool,shape=[]) # Training flag\n",
    "        # Initializers\n",
    "        self.fully_init  = tf.random_normal_initializer(stddev=0.01)\n",
    "        self.bias_init   = tf.constant_initializer(0.)\n",
    "        self.bn_init     = {'beta': tf.constant_initializer(0.),\n",
    "                           'gamma': tf.random_normal_initializer(1., 0.01)}\n",
    "        self.bn_params   = {'is_training':self.is_training,'decay':0.9,'epsilon':1e-5,\n",
    "                           'param_initializers':self.bn_init,'updates_collections':None}\n",
    "        # Build graph\n",
    "        with tf.variable_scope(self.name,reuse=False) as scope:\n",
    "            with slim.arg_scope([slim.fully_connected],activation_fn=self.actv,\n",
    "                                weights_initializer=self.fully_init,biases_initializer=self.bias_init,\n",
    "                                normalizer_fn=self.bn,normalizer_params=self.bn_params,\n",
    "                                weights_regularizer=None):\n",
    "                _net = self.x\n",
    "                for h_idx in range(len(self.hdims)): # Loop over hidden layers\n",
    "                    _hdim = self.hdims[h_idx]\n",
    "                    _net = slim.fully_connected(_net,_hdim,scope='lin'+str(h_idx))\n",
    "                    _net = slim.dropout(_net,keep_prob=self.kp,is_training=self.is_training\n",
    "                                        ,scope='dr'+str(h_idx))\n",
    "                self.feat = _net # [N x Q]\n",
    "                # Class allocation probability \n",
    "                self.pi_logits = slim.fully_connected(self.feat,self.kmix,scope='pi_logits')\n",
    "                self.pi = tf.nn.softmax(self.pi_logits,dim=1)\n",
    "                # means (data x dim x mixture)\n",
    "                self._mu = slim.linear(self.feat,self.kmix*self.ydim,scope='mu_flatten'\n",
    "                                      ,biases_initializer=tf.random_uniform_initializer(minval=-2,maxval=+2))\n",
    "                self.mu = tf.reshape(self._mu,shape=[-1,self.ydim,self.kmix])\n",
    "                # varainces (data x dim x mixture)\n",
    "                self.sigma_logits = slim.fully_connected(self.feat,self.kmix*self.ydim,scope='sigma_logits')\n",
    "                if self.sigmax == 0:\n",
    "                    self._sigma =tf.exp(self.sigma_logits)\n",
    "                else:\n",
    "                    self._sigma = self.sigmax*tf.nn.sigmoid(self.sigma_logits)\n",
    "                # _sigma = tf.exp(_sigma_logits)\n",
    "                self.sigma = tf.reshape(self._sigma,shape=[-1,self.ydim,self.kmix]) # [N x D x K]\n",
    "                \n",
    "    def build_graph(self):\n",
    "        y = self.t\n",
    "        pi = self.pi\n",
    "        mu = self.mu\n",
    "        sigma = self.sigma\n",
    "        yrepeat = tf.tile(y[:,:,tf.newaxis],[1,1,self.kmix]) # (N x D x K)\n",
    "        self.quadratics = -0.5*tf.reduce_sum(((yrepeat-mu)/sigma)**2,axis=1) # (N x K)\n",
    "        self.logdet = -0.5*tf.reduce_sum(tf.log(sigma),axis=1) # (N x K)\n",
    "        self.logconstant = - 0.5*self.ydim*tf.log(2*np.pi) # (1)\n",
    "        self.logpi = tf.log(pi) # (N x K)\n",
    "        self.exponents = self.quadratics + self.logdet + self.logconstant + self.logpi\n",
    "        self.logprobs = tf.reduce_logsumexp(self.exponents,axis=1) # (N)\n",
    "        self.gmm_prob = tf.exp(self.logprobs) # (N)\n",
    "        self.gmm_nll  = -tf.reduce_mean(self.logprobs) # (1)\n",
    "        # Weight decay \n",
    "        # _g_vars = tf.global_variables()\n",
    "        _g_vars = tf.trainable_variables()\n",
    "        self.c_vars = [var for var in _g_vars if '%s/'%(self.name) in var.name]\n",
    "        self.l2_reg = self.l2_reg_coef*tf.reduce_sum(tf.stack([tf.nn.l2_loss(v) for v in self.c_vars])) # [1]\n",
    "        # Loss and optimizer \n",
    "        self.loss_total = self.gmm_nll + self.l2_reg\n",
    "        USE_ADAM = False\n",
    "        if USE_ADAM:\n",
    "            self.optm = tf.train.AdamOptimizer(learning_rate=self.lr\n",
    "                , beta1=0.9, beta2=0.999, epsilon=1e-0).minimize(self.loss_total)\n",
    "        else:\n",
    "            self.optm = tf.train.MomentumOptimizer(learning_rate=self.lr\n",
    "                                                   ,momentum=0.0).minimize(self.loss_total)\n",
    "        # Compute regression loss \n",
    "        _N = tf.shape(self.x)[0] # Number of data\n",
    "        maxIdx = tf.argmax(input=pi,axis=1, output_type=tf.int32) # Argmax Index [N]\n",
    "        # maxIdx = 0*tf.ones_like(maxIdx) # <== ???\n",
    "        coords = tf.stack([tf.transpose(gv) for gv in tf.meshgrid(tf.range(_N),tf.range(self.ydim))] + \n",
    "                          [tf.reshape(tf.tile(maxIdx[:,tf.newaxis],[1,self.ydim]),shape=(_N,self.ydim))]\n",
    "                          ,axis=2) # [N x D x 3]\n",
    "        self.mu_bar = tf.gather_nd(mu,coords) # [N x D]\n",
    "        self.fit_mse = tf.reduce_sum(tf.pow(self.mu_bar-self.t, 2))/(tf.cast(_N,tf.float32)) # Fitting error (mse)\n",
    "        \n",
    "    # Check parameters\n",
    "    def check_params(self):\n",
    "        _g_vars = tf.global_variables()\n",
    "        self.g_vars = [var for var in _g_vars if '%s/'%(self.name) in var.name]\n",
    "        if self.VERBOSE:\n",
    "            print (\"==== Global Variables ====\")\n",
    "        for i in range(len(self.g_vars)):\n",
    "            w_name  = self.g_vars[i].name\n",
    "            w_shape = self.g_vars[i].get_shape().as_list()\n",
    "            if self.VERBOSE:\n",
    "                print (\" [%02d] Name:[%s] Shape:[%s]\" % (i,w_name,w_shape))\n",
    "    \n",
    "    # Sampler\n",
    "    def sampler(self,_sess,_x,n_samples=10,_USE_ARGMAX=False,_MU_ONLY=False):\n",
    "        pi, mu, sigma = _sess.run([self.pi, self.mu, self.sigma],\n",
    "                                  feed_dict={self.x:_x,self.kp:1.0,self.is_training:False})\n",
    "        n_points = _x.shape[0]\n",
    "        _y_sampled = np.zeros([n_points,self.ydim,n_samples])\n",
    "        for i in range(n_points):\n",
    "            for j in range(n_samples):\n",
    "                if _USE_ARGMAX: # Use the most likely mixture\n",
    "                    k = np.argmax(pi[i,:])\n",
    "                else:\n",
    "                    k = np.random.choice(self.kmix,p=pi[i,:])\n",
    "                if _MU_ONLY: # Plot mu only\n",
    "                    _y_sampled[i,:,j] = mu[i,:,k]\n",
    "                else: # Sample from Gaussian\n",
    "                    _y_sampled[i,:,j] = mu[i,:,k] + np.random.randn(1,self.ydim)*np.sqrt(sigma[i,:,k])\n",
    "        return _y_sampled\n",
    "    \n",
    "    # Save \n",
    "    def save(self,_sess,_savename=None):\n",
    "        \"\"\" Save name \"\"\"\n",
    "        if _savename==None:\n",
    "            _savename='../net/net_%s.npz'%(self.name)\n",
    "        \"\"\" Get global variables \"\"\"\n",
    "        self.g_wnames,self.g_wvals,self.g_wshapes = [],[],[]\n",
    "        for i in range(len(self.g_vars)):\n",
    "            curr_wname = self.g_vars[i].name\n",
    "            curr_wvar  = [v for v in tf.global_variables() if v.name==curr_wname][0]\n",
    "            curr_wval  = _sess.run(curr_wvar)\n",
    "            curr_wval_sqz  = curr_wval.squeeze()\n",
    "            self.g_wnames.append(curr_wname)\n",
    "            self.g_wvals.append(curr_wval_sqz)\n",
    "            self.g_wshapes.append(curr_wval.shape)\n",
    "        \"\"\" Save \"\"\"\n",
    "        np.savez(_savename,g_wnames=self.g_wnames,g_wvals=self.g_wvals,g_wshapes=self.g_wshapes)\n",
    "        if self.VERBOSE:\n",
    "            print (\"[%s] Saved. Size is [%.4f]MB\" % \n",
    "                   (_savename,os.path.getsize(_savename)/1000./1000.))\n",
    "            \n",
    "    # Save \n",
    "    def save_final(self,_sess,_savename=None):\n",
    "        \"\"\" Save name \"\"\"\n",
    "        if _savename==None:\n",
    "            _savename='../net/net_%s_final.npz'%(self.name)\n",
    "        \"\"\" Get global variables \"\"\"\n",
    "        self.g_wnames,self.g_wvals,self.g_wshapes = [],[],[]\n",
    "        for i in range(len(self.g_vars)):\n",
    "            curr_wname = self.g_vars[i].name\n",
    "            curr_wvar  = [v for v in tf.global_variables() if v.name==curr_wname][0]\n",
    "            curr_wval  = _sess.run(curr_wvar)\n",
    "            curr_wval_sqz  = curr_wval.squeeze()\n",
    "            self.g_wnames.append(curr_wname)\n",
    "            self.g_wvals.append(curr_wval_sqz)\n",
    "            self.g_wshapes.append(curr_wval.shape)\n",
    "        \"\"\" Save \"\"\"\n",
    "        np.savez(_savename,g_wnames=self.g_wnames,g_wvals=self.g_wvals,g_wshapes=self.g_wshapes)\n",
    "        print (\"[%s] Saved. Size is [%.4f]MB\" % \n",
    "               (_savename,os.path.getsize(_savename)/1000./1000.))\n",
    "        \n",
    "    # Restore\n",
    "    def restore(self,_sess,_loadname=None):\n",
    "        if _loadname==None:\n",
    "            _loadname='../net/net_%s_final.npz'%(self.name)\n",
    "        l = np.load(_loadname)\n",
    "        g_wnames = l['g_wnames']\n",
    "        g_wvals  = l['g_wvals']\n",
    "        g_wshapes = l['g_wshapes']\n",
    "        for widx,wname in enumerate(g_wnames):\n",
    "            curr_wvar  = [v for v in tf.global_variables() if v.name==wname][0]\n",
    "            _sess.run(tf.assign(curr_wvar,g_wvals[widx].reshape(g_wshapes[widx])))\n",
    "        if self.VERBOSE:\n",
    "            print (\"Weight restored from [%s] Size is [%.4f]MB\" % \n",
    "                   (_loadname,os.path.getsize(_loadname)/1000./1000.))\n",
    "    \n",
    "    # Save to mat file\n",
    "    def save2mat(self,_xdata='',_ydata='',_yref=''):\n",
    "        # Save weights to mat file so that MATLAB can use it.\n",
    "        npzPath = '../net/net_%s.npz'%(self.name)\n",
    "        l = np.load(npzPath)\n",
    "        g_wnames = l['g_wnames']\n",
    "        g_wvals  = l['g_wvals']\n",
    "        g_wshapes = l['g_wshapes']\n",
    "        D = {}\n",
    "        for widx,wname in enumerate(g_wnames):\n",
    "            cName = wname.replace(':0','')\n",
    "            cName = cName.replace(self.name+'/','')\n",
    "            cName = cName.replace('/','_')\n",
    "            cVal = g_wvals[widx].reshape(g_wshapes[widx])\n",
    "            D[cName] = cVal\n",
    "            # Do not print out..\n",
    "            # if self.VERBOSE: print (\"name is [%s] shape is %s.\"%(cName,cVal.shape,))\n",
    "        # Save data\n",
    "        if _xdata!='': D['xdata']=_xdata\n",
    "        if _ydata!='': D['ydata']=_ydata\n",
    "        if _yref!='': D['yref']=_yref\n",
    "        # Save dictionary D to the mat file\n",
    "        matPath = '../data/net_%s.mat'%(self.name)\n",
    "        sio.savemat(matPath,D)\n",
    "        if self.VERBOSE: print (\"[%s] saved.\"%(matPath))\n",
    "        \n",
    "    # Save to mat file\n",
    "    def save2mat_final(self,_xdata='',_ydata='',_yref=''):\n",
    "        # Save weights to mat file so that MATLAB can use it.\n",
    "        npzPath = '../net/net_%s_final.npz'%(self.name)\n",
    "        l = np.load(npzPath)\n",
    "        g_wnames = l['g_wnames']\n",
    "        g_wvals  = l['g_wvals']\n",
    "        g_wshapes = l['g_wshapes']\n",
    "        D = {}\n",
    "        for widx,wname in enumerate(g_wnames):\n",
    "            cName = wname.replace(':0','')\n",
    "            cName = cName.replace(self.name+'/','')\n",
    "            cName = cName.replace('/','_')\n",
    "            cVal = g_wvals[widx].reshape(g_wshapes[widx])\n",
    "            D[cName] = cVal\n",
    "            if self.VERBOSE: print (\"name is [%s] shape is %s.\"%(cName,cVal.shape,))\n",
    "        # Save data\n",
    "        if _xdata!='': D['xdata']=_xdata\n",
    "        if _ydata!='': D['ydata']=_ydata\n",
    "        if _yref!='': D['yref']=_yref\n",
    "        # Save dictionary D to the mat file\n",
    "        matPath = '../data/net_%s_final.mat'%(self.name)\n",
    "        sio.savemat(matPath,D)\n",
    "        print (\"[%s] Saved. Size is [%.4f]MB\" % \n",
    "               (matPath,os.path.getsize(matPath)/1000./1000.))\n",
    "        \n",
    "    # Train\n",
    "    def train(self,_sess,_x,_y,_yref='',_lr=1e-3,_batchSize=512,_maxEpoch=1e4,_kp=1.0\n",
    "              ,_LR_SCHEDULE=True\n",
    "              ,_PRINT_EVERY=20,_PLOT_EVERY=20\n",
    "              ,_SAVE_TXT=True,_SAVE_BEST_NET=True,_SAVE_FINAL=True):\n",
    "        \n",
    "        # Reference training data \n",
    "        _x_train,_y_train = _x,_y\n",
    "        \n",
    "        # Iterate\n",
    "        if _PRINT_EVERY == 0: print_period = 0\n",
    "        else: print_period = _maxEpoch//_PRINT_EVERY\n",
    "        if _PLOT_EVERY == 0: plot_period = 0\n",
    "        else: plot_period = _maxEpoch//_PLOT_EVERY\n",
    "        \n",
    "        maxIter = max(_x_train.shape[0]//_batchSize, 1)\n",
    "        bestLossVal = np.inf\n",
    "        if _SAVE_TXT:\n",
    "            txtName = ('../res/res_%s.txt'%(self.name));f = open(txtName,'w') # Open txt file\n",
    "            print_n_txt(_f=f,_chars='Text name: '+txtName,_DO_PRINT=True)\n",
    "        for epoch in range((int)(_maxEpoch)+1): # For every epoch\n",
    "            _x_train,_y_train = shuffle(_x_train,_y_train)\n",
    "            for iter in range(maxIter): # For every iteration\n",
    "                start,end = iter*_batchSize,(iter+1)*_batchSize\n",
    "                if _LR_SCHEDULE:\n",
    "                    if epoch < 0.5*_maxEpoch:\n",
    "                        lr_use = _lr\n",
    "                    elif epoch < 0.75*_maxEpoch:\n",
    "                        lr_use = _lr/5.\n",
    "                    else:\n",
    "                        lr_use = _lr/10.\n",
    "                else:\n",
    "                    lr_use = _lr\n",
    "                feeds = {self.x:_x_train[start:end,:],self.t:_y_train[start:end,:]\n",
    "                         ,self.kp:_kp,self.lr:lr_use,self.is_training:True}\n",
    "                # Optimize \n",
    "                _sess.run(self.optm,feeds)\n",
    "            \n",
    "            # Track the Best result\n",
    "            BEST_FLAG = False\n",
    "            check_period = _maxEpoch//100\n",
    "            if (epoch%check_period)==0:\n",
    "                feeds = {self.x:_x,self.t:_y,self.kp:1.0,self.is_training:False}\n",
    "                opers = [self.loss_total,self.gmm_nll,self.l2_reg]\n",
    "                lossVal,gmm_nll,l2_reg = _sess.run(opers,feeds)\n",
    "                if (lossVal < bestLossVal) & (epoch >= 3):\n",
    "                    bestLossVal = lossVal\n",
    "                    BEST_FLAG = True\n",
    "                    if _SAVE_BEST_NET:\n",
    "                        self.save(_sess) # Save the current best model \n",
    "                        self.save2mat(_xdata=_x,_ydata=_y,_yref=_yref)\n",
    "            \n",
    "            # Print current result \n",
    "            if (print_period!=0) and ((epoch%print_period)==0 or (epoch==(_maxEpoch-1))): # Print \n",
    "                feeds = {self.x:_x,self.t:_y,self.kp:1.0,self.is_training:False}\n",
    "                opers = [self.loss_total,self.gmm_nll,self.l2_reg]\n",
    "                lossVal,gmm_nll,l2_reg = _sess.run(opers,feeds)\n",
    "                if _SAVE_TXT:\n",
    "                    strTemp = (\"[%d/%d] loss:%.3f(gmm:%.3f+l2:%.3f) bestLoss:%.3f\"\n",
    "                               %(epoch,_maxEpoch,lossVal,gmm_nll,l2_reg,bestLossVal))\n",
    "                    print_n_txt(_f=f,_chars=strTemp,_DO_PRINT=self.VERBOSE)\n",
    "                else:\n",
    "                    if self.VERBOSE:\n",
    "                        print (\"[%d/%d] loss:%.3f(gmm:%.3f+l2:%.3f) bestLoss:%.3f\"\n",
    "                                   %(epoch,_maxEpoch,lossVal,gmm_nll,l2_reg,bestLossVal))\n",
    "\n",
    "            # Plot current result \n",
    "            if (plot_period!=0) and ((epoch%plot_period)==0 or (epoch==(_maxEpoch-1))): # Plot\n",
    "                feeds = {self.x:_x,self.t:_y,self.kp:1.0,self.is_training:False}\n",
    "                opers = [self.loss_total,self.gmm_nll,self.l2_reg]\n",
    "                lossVal,gmm_nll,l2_reg = _sess.run(opers,feeds)\n",
    "                 \n",
    "                # Plot sampled outputs\n",
    "                nSample = 3\n",
    "                ytest = self.sampler(_sess=_sess,_x=_x,n_samples=nSample\n",
    "                                     ,_USE_ARGMAX=False,_MU_ONLY=False)\n",
    "                x_plot,y_plot = _x[:,0],_y[:,0] # Traning data \n",
    "                plt.figure(figsize=(8,4));\n",
    "                plt.axis([np.min(x_plot),np.max(x_plot),np.min(y_plot)-0.1,np.max(y_plot)+0.1])\n",
    "                if _yref != '': plt.plot(x_plot,_yref[:,0],'r.') # Plot reference\n",
    "                plt.plot(x_plot,y_plot,'k.') # Plot training data\n",
    "                for i in range(nSample): \n",
    "                    plt.plot(_x,ytest[:,0,i],'b.')\n",
    "                plt.title(\"[%d/%d] name:[%s] lossVal:[%.3e]\"%(epoch,_maxEpoch,self.name,lossVal))\n",
    "                \n",
    "                # Plot most-likely mean function\n",
    "                ytest = self.sampler(_sess=_sess,_x=_x,n_samples=1\n",
    "                                     ,_USE_ARGMAX=True,_MU_ONLY=True)\n",
    "                x_plot,y_plot = _x[:,0],_y[:,0] # Traning data \n",
    "                plt.figure(figsize=(8,4));\n",
    "                plt.axis([np.min(x_plot),np.max(x_plot),np.min(y_plot)-0.1,np.max(y_plot)+0.1])\n",
    "                if _yref != '': plt.plot(x_plot,_yref[:,0],'r.') # Plot reference\n",
    "                plt.plot(x_plot,y_plot,'k.') # Plot training data\n",
    "                plt.plot(_x,ytest[:,0,0],'b-')\n",
    "                plt.title(\"[%d/%d] name:[%s] lossVal:[%.3e]\"%(epoch,_maxEpoch,self.name,lossVal))\n",
    "                plt.show()\n",
    "                \n",
    "        # Save fianl weights\n",
    "        if _SAVE_FINAL:\n",
    "            self.save_final(_sess)\n",
    "            self.save2mat_final(_xdata=_x,_ydata=_y,_yref=_yref)\n",
    "    \n",
    "    # Test\n",
    "    def test(self,_sess,_xdata,_ydata,_yref,_xtest\n",
    "             ,_titleStr,_PLOT_TRAIN=True,_PLOT_RES=True,_SAVE_FIG=False):\n",
    "        nSample = 1\n",
    "        ytest = self.sampler(_sess=_sess,_x=_xtest,n_samples=nSample\n",
    "                            ,_USE_ARGMAX=True,_MU_ONLY=True)\n",
    "        # Plot \n",
    "        if _PLOT_TRAIN:\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.axis([np.min(_xdata),np.max(_xdata),np.min(_ydata),np.max(_ydata)])\n",
    "            plt.plot(_xdata,_ydata,'k.')\n",
    "            plt.xlabel('Input',fontsize=13);plt.ylabel('Output',fontsize=13)\n",
    "            plt.title('Training Data for a Regression Task',fontsize=16); \n",
    "            if _SAVE_FIG: \n",
    "                plt.savefig('../fig/fig_%s_data.png'%(self.name)); plt.show()\n",
    "            else: \n",
    "                plt.show()\n",
    "        # Plot \n",
    "        if _PLOT_RES:\n",
    "            fig = plt.figure(figsize=(6,4))\n",
    "            plt.axis([np.min(_xdata),np.max(_xdata),np.min(_ydata),np.max(_ydata)])\n",
    "            ht,=plt.plot(_xdata,_yref,'r.'); \n",
    "            hd,=plt.plot(_xdata,_ydata,'k.')\n",
    "            for i in range(nSample): \n",
    "                hf,=plt.plot(_xtest,ytest[:,0,i],'b-')\n",
    "            plt.xlabel('Input',fontsize=13);plt.ylabel('Output',fontsize=13)\n",
    "            plt.title('%s'%(_titleStr),fontsize=16)\n",
    "            plt.legend([ht,hd,hf],['Target function','Training data','Fitting result']\n",
    "                       ,fontsize=15,loc='upper left')\n",
    "            if _SAVE_FIG:\n",
    "                plt.savefig('../fig/fig_%s_res.png'%(self.name)); plt.show()\n",
    "            else:\n",
    "                plt.show()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print (\"mdn_reg_class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MDN for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Training data\n",
    "    dataType = 'cosexp' # ['cosexp','linear','step']\n",
    "    oRate = 0.4\n",
    "    measVar = 1e-8\n",
    "    x,y,t=data4reg(_type=dataType,_n=1000,_oRange=[-1.0,+3.0],_oRate=oRate,measVar=measVar)\n",
    "    xtest = np.linspace(start=-3,stop=3,num=1000).reshape((-1,1))\n",
    "    # plot_1dRegData(_x=x,_y=y,_t=t,_type='Training data [%s] function'%(dataType),_figSize=(8,4))\n",
    "    \n",
    "    # Make graph\n",
    "    tf.reset_default_graph(); sess = gpusession()\n",
    "    tf.set_random_seed(0); np.random.seed(0)        \n",
    "    MDN =  mdn_reg_class(_name='MDN_%s_oRate%02d_var%.1e'%(dataType,oRate*100,measVar)\n",
    "                         ,_xdim=1,_ydim=1,_hdims=[32,32],_sigmax=1\n",
    "                         ,_kmix=5,_actv=tf.nn.relu,_bn=slim.batch_norm\n",
    "                         ,_l2_reg_coef=1e-5,_GPU_ID=0,_VERBOSE=False)\n",
    "    sess.run(tf.global_variables_initializer()) # Initialize variables\n",
    "    \n",
    "    # Train \n",
    "    DO_TRAIN = True \n",
    "    if DO_TRAIN:\n",
    "        MDN.train(_sess=sess,_x=x,_y=y,_yref=t \n",
    "               ,_lr=1e-3,_batchSize=256,_maxEpoch=1e4,_kp=1.0\n",
    "               ,_LR_SCHEDULE=True\n",
    "               ,_PRINT_EVERY=10,_PLOT_EVERY=10\n",
    "               ,_SAVE_TXT=True,_SAVE_BEST_NET=True)\n",
    "        print (\"Train done.\") \n",
    "    else: \n",
    "        MDN.restore(sess)\n",
    "        print (\"Network restored.\")\n",
    "        \n",
    "    # Test \n",
    "    MDN.test(_sess=sess,_xdata=x,_ydata=y,_yref=t,_xtest=xtest\n",
    "           ,_titleStr='Final Best Result'\n",
    "           ,_PLOT_TRAIN=True,_PLOT_RES=True,_SAVE_FIG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
